\section{Analisi dei dati e classificatori utilizzati}

In questa sezione verrà riportato lo studio effettuato sul dataset.
% Ogni sottosezione tratterà di uno specifico classificatore, dei suoi risultati e degli esperimenti fatti per migliorarne il modello.

\subsection{Considerazioni sugli attributi}

Studiando la composizione dei dati per selezionare le principali tecniche da applicare,
la prima cosa che risulta visibile all'apertura del dataset è sicuramente il suo sbilanciamento nelle classi di output:
come mostrato in~\Cref{fig:classes}, su 100 pazienti in esame, solo 12 risultano compromessi.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\textwidth]{fig/classes.eps}%
  \caption{%
    L'istogramma rappresenta i valori assunti dall'attributo classe:
    la colonna blu rappresenta le diagnosi di fertilità normale,
    quella rossa gli esami che evidenziano potenziali problematiche.
  }%
  \label{fig:classes}
\end{figure}

Questo disequilibrio tra le classi mette in difficoltà i modelli più semplici;
al fine di ottenere risultati validi, si è messo alla prova diverse configurazioni parametriche.

Per quanto riguarda gli altri attributi, di seguito sono riportati in elenco brevi considerazioni sulle analisi visuali.

\begin{itemize}
  \item \texttt{season}:
    La frequenza di esami con esito problematico tendono ad aumentare leggermente durante estate e inverno;
    questo potrebbe essere dovuto alle condizioni di forte caldo o gelo tipiche di quelle stagioni.
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.85\textwidth]{fig/season.eps}
    \end{figure}
  \item \texttt{age}:
    Discretizzando l'attributo su 18 valori, la distribuzione dei valori risulta non omogenea:
    tendono a essere molto più frequenti i pazienti con età più vicina a 18 anni che 36.
    Inoltre, i casi di infertilità tendono a concentrarsi dopo i 24 anni, con picco proprio su tale anno.
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.85\textwidth]{fig/age-discrete.eps}
    \end{figure}
  \item \texttt{childish-disease}:
    I casi di fertilità e infertilità risultano abbastanza bilanciati sulle due colonne dell'istogramma,
    mentre gli individui affetti da problematiche durante l'infanzia sono molti meno rispetto agli altri;
    si può supporre quindi che questo attributo non sia particolarmente rilevante ai fini di una diagnosi della fertilità.
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.85\textwidth]{fig/disease.eps}
    \end{figure}
  \item \texttt{surgical-intervention}:
    L'istogramma risulta bilanciato sia rispetto all'attributo che rispetto alla classe;
    si può quindi supporre che la presenza di un intervento chirurgico non sia strettamente correlata alla fertilità.
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.85\textwidth]{fig/surgical.eps}
    \end{figure}
  \item \texttt{fever}:
    I dati risultano sbilanciati, con una maggiore frequenza per coloro che hanno avuto un episodio di febbre alta a oltre tre mesi di distanza dall'esame;
    tale squilibrio può essere considerato normale, dato che i periodi sono effettivamente di differente lunghezza.
    Considerato ciò, la distribuzione degli esami problematici risulta bilanciata tra le colonne dell'istogramma rispetto al numero di elementi per ogni colonna.
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.85\textwidth]{fig/fever.eps}
    \end{figure}
  \item \texttt{alcoholic}:
    I dati risultano sbilanciati con una concentrazione maggiore verso i valori che indicano un raro consumo di alcool.
    Tra coloro che consumano alcool una o più volte a settimana e quelli che invece si dichiarano astemi, il tasso di esami problematici tende a crescere per la prima categoria rispetto alla seconda, dunque potrebbe esistere una correlazione.
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.85\textwidth]{fig/alcool.eps}
    \end{figure}
  \item \texttt{smoking}:
    Rispetto alle abitudini legate al fumo, i potenziali problemi di sterilità risultano più frequenti negli individui fumatori, occasionali o meno, rispetto ai non fumatori.
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.85\textwidth]{fig/smoke.eps}
    \end{figure}
  \item \texttt{sitting}:
    Il dataset contiene più dati aventi valori nel range \(1\)-\(8\) rispetto a \(8\)-\(16\);
    all'interno del primo range gli esami problematici tendono a concentrarsi verso i valori più alti, dunque si può considerare il tempo trascorso seduti al giorno come legato ai problemi di fertilità.
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.85\textwidth]{fig/sit-discrete.eps}
    \end{figure}
\end{itemize}

\subsection{Misure di performance dei classificatori}

Prima di partire con le analisi, occorre stabilire i criteri di misura delle performance dei vari classificatori:
a tale scopo si è considerato in primo luogo la \emph{Confusion Matrix} prodotta da ogni modello, oltre ai valori di \emph{precision} e \emph{recall} per le classi in gioco, attribuendo un maggiore peso ai valori relativi alla classe ``\texttt{O}'' rispetto a ``\texttt{N}'' e infine del valore della \emph{}{ROC}\@.

Come modalità di test, si è scelto di applicare \emph{K-Fold Cross-Validation} piuttosto che lo splitting statico dei dati in training set e test set, poiché pensato appositamente per dataset di piccole dimensioni come questo.

\subsection{Decision Tree}\label{subsec:tree}

La prima tecnica di classificazione testata è stata il Decision Tree.
In particolare, si è scelto di usare \texttt{J48}, implementazione dell'algoritmo \emph{C4.5};
esso realizza un albero binario a cui possono essere applicate tecniche di \emph{post pruning}
per ridurre le dimensioni dell'albero e l'errore commesso dal classificatore.

In primo luogo si è provato a generare un modello applicando i parametri standard impostati da Weka, ottenendo così i risultati riportati in~\Cref{fig:j48}.

\begin{figure}[H]
  \centering
  \adjincludegraphics[width=\linewidth,trim=0 0 0 {.3\height},clip]{fig/j48.eps}%
  \caption{Output di \texttt{J48} eseguito tramite Weka}%
  \label{fig:j48}
\end{figure}

Com'è possibile notare, il classificatore costruisce un modello poco valido:
per quanto \emph{accuracy}, \emph{precision} e \emph{recall} per la classe ``\texttt{N}'' abbiano valori piuttosto elevati,
i corrispondenti per ``\texttt{O}'' risultano tendenti a \(0\).
Anche il valore di \emph{ROC}, indicatore principale della bontà di un modello di classificazione, risulta estremamente basso.

Osservando la struttura dell'albero costruito, è piuttosto chiaro il motivo di valori tanto bassi:
l'albero infatti è costruito da un'unica foglia i cui valori sono assegnati alla classe ``\texttt{N}'', causando così la situazione sopra descritta.

Ovviamente questo modello non risultava di una qualità soddisfacente, probabilmente a causa del post pruning,
il quale, in presenza di un tale sbilanciamento nella frequenza delle classi, tende a ridurre l'albero di classificazione a singola foglia.
Per porre rimedio a questa cosa si è provato ad aumentare e diminuire il parametro \texttt{confidenceFactor}, responsabile di accentuare o smussare le operazioni di pruning;
anche però variando questo parametro i risultati ottenuti non sono stati particolarmente differenti.

La situazione è decisamente migliorata disattivando il pruning (tramite parametro \texttt{unpruned}):
questa scelta ha finalmente prodotto un risultato notevolmente differente dai precedenti, come è possibile vedere in~\Cref{fig:j48-unpruned}.

\begin{figure}[H]
  \centering
  \begin{subfigure}{0.35\textwidth}
    \centering
    \adjincludegraphics[width=\linewidth,trim=0 {.37\height} {.55\width} {.25\height},clip]{fig/j48-unpruned.eps}%
    \label{fig:j48-unpruned:tree}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.6\textwidth}
    \centering
    \adjincludegraphics[width=\linewidth,trim=0 0 {.16\width} {.65\height},clip]{fig/j48-unpruned.eps}%
    \label{subfig:j48-unpruned:result}
  \end{subfigure}
  \caption{Albero di classificazione e output ottenuto con \texttt{J48} \emph{unpruned}}%
  \label{fig:j48-unpruned}
\end{figure}

Il risultato del classificatore è sicuramente migliore rispetto alla sua versione \emph{pruned}, tuttavia rimane ancora abbastanza insoddisfacente.

Sperimentando ulteriormente con la versione \emph{unpruned} di \texttt{J48},
abbassando il numero minimo di elementi per foglia a \(1\) il valore di \emph{recall} per la classe \texttt{O} e di \emph{True Positive} si alzava,
ma il valore di \emph{ROC} e \emph{precision} si abbassavano.

Si può dunque concludere che il classificatore \texttt{J48} non garantisce risultati ottimali sopra questo dataset, soprattutto a causa del grande sbilanciamento tra le distribuzioni delle classi.

Disabilitando il post pruning e abbassando il numero minimo di elementi per foglia a \(1\), si può classificare correttamente poco meno della metà degli elementi appartenente a \texttt{O},
classe più difficile da individuare ma allo stesso tempo più rilevante rispetto al dominio dei dati del sistema.

\subsection{Classificatori Bayesiani: \emph{Naïve Bayes}}\label{subsec:bayes}

Per tentare un approccio differente, ho provato a costruire un modello basato sui classificatori bayesiani,
approccio che ignora le relazioni tra gli attributi in favore della frequenza di certi valori rispetto alle classi in gioco.

Il classificatore specifico scelto per il dataset è stato \emph{Naïve Bayes} nella sua implementazione fornita da Weka (chiamata appunto \texttt{NaiveBayes});
costruendo il modello utilizzando i parametri standard impostati dalla workbench, sono stati ottenuti i risultati mostrati in~\Cref{fig:bayes}.

\begin{figure}[H]
  \centering
  \adjincludegraphics[width=\linewidth,trim=0 0 0 {.76\height},clip]{fig/bayes.eps}%
  \caption{Output di \texttt{NaiveBayes} eseguito tramite Weka}%
  \label{fig:bayes}
\end{figure}

Analizzando i risultati di questo classificatore, si possono fare diverse considerazioni:
partendo dall'osservazione della \emph{confusion matrix} è possibile vedere come praticamente tutti i dati vengano assegnati alla classe ``\texttt{N}'', mentre ad ``\texttt{O}'' viene assegnato un solo elemento;
ciò è ulteriormente confermato dai valori i \emph{precision} e \emph{recall} per la classe ``\texttt{O}'', che risultano essere \(0\).

Infine, osservando \emph{ROC} si ha la conferma definitiva che il modello costruito sia decisamente inefficiente e poco performante.

Le ragioni dietro alla poca efficienza del modello bayesiano per questo problema possono essere ricondotte alla mancanza dei valori di distribuzione delle probabilità reali per le classi e alla potenziale mancanza di indipendenza statistica tra attributi.
Questi fattori, combinati allo sbilanciamento dei dati nel dataset, da cui vengono estratte le distribuzioni di probabilità necessarie al classificatore in mancanza di quelle reali, rendono inefficace il modello bayesiano su questo dataset.

\subsection{Classificatori Lazy: \emph{k-NN}}\label{subsec:ibk}

Altra famiglia utilizzata è stata quella dei \emph{classificatori Instance-based} o \emph{Lazy}.
La particolarità di queste tecniche è la totale assenza di modello, sostituito da procedure di natura induttiva.

Tra tutti i classificatori disponibili in questa famiglia, si è scelto di utilizzare \texttt{IBk}, implementazione in Weka dell'algoritmo \emph{k-NN};
per questo classificatore è possibile impostare diversi parametri, come il numero di vicini da considerare e la metrica da utilizzare nel calcolo della distanza.

\subsubsection{Utilizzando gli attributi nominali come tali}\label{subsub:ibk:nominal}

Applicando i parametri default di Weka, ovvero \texttt{KNN=1} e \emph{distanza euclidea}, si ottengono i risultati riportati in~\Cref{fig:ibk:1}.

\begin{figure}[H]
  \centering
  \adjincludegraphics[width=\linewidth,trim=0 0 {.285\width} {.32\height},clip]{fig/ibk.eps}%
  \caption{Output di \texttt{IBk} eseguito tramite Weka}%
  \label{fig:ibk:1}
\end{figure}

I risultati ottenuti da questo modello risultano non particolarmente buoni, tuttavia i valori di \emph{Confusion Matrix}, \emph{ROC}, \emph{Precision} e \emph{Recall} per la classe ``\texttt{O}'' sono comunque migliori rispetto a quelli ottenuti nei tentativi precedenti.
Si è ritenuto dunque che il modello possa essere migliorato utilizzando valori differenti per i parametri sopra descritti.

Mantenendo la \emph{distanza euclidea} come metrica, si è provato a variare il valore di K tra i numeri dispari compresi tra \(3\) e \(11\);
l'unico risultato rilevante è con \texttt{KNN=9}, per il quale si raggiunge la massimizzazione del valore di \emph{ROC} (\Cref{fig:ibk:9}).

%     % \begin{figure}[H]
%     %   \centering
%     %   \adjincludegraphics[width=\linewidth,trim=0 0 {.285\width} {.32\height},clip]{fig/ibk5.eps}%
%     %   \caption{Output di \texttt{IBk} con \texttt{KNN=5}}%
%     %   \label{fig:ibk:5}
%     % \end{figure}
%   \item
%     con \texttt{KNN=3} si ottengono i massimi valori di \emph{Precision} e \emph{Recall} per la classe ``\texttt{O}'' (\Cref{fig:ibk:3}).
%     % \begin{figure}[H]
%     %   \centering
%     %   \adjincludegraphics[width=\linewidth,trim=0 0 {.285\width} {.32\height},clip]{fig/ibk3.eps}%
%     %   \caption{Output di \texttt{IBk} con \texttt{KNN=3}}%
%     %   \label{fig:ibk:3}
%     % \end{figure}
% \end{itemize}

% \begin{figure}[H]
%   \centering
%   \adjincludegraphics[width=\linewidth,trim=0 0 {.285\width} {.32\height},clip]{fig/ibk3.eps}%
%   \caption{Output di \texttt{IBk} con \texttt{KNN=3}}%
%   \label{fig:ibk:3}
% \end{figure}

\begin{figure}[H]
  \centering
  \adjincludegraphics[width=\linewidth,trim=0 0 {.285\width} {.32\height},clip]{fig/ibk9.eps}%
  \caption{Output di \texttt{IBk} con \texttt{KNN=9}}%
  \label{fig:ibk:9}
\end{figure}

Di fatto, anche cambiando il numero dei vicini da considerare si può vedere che il modello arranca ancora nel riconoscimento degli elementi della classe ``\texttt{O}''.

\subsubsection{Utilizzando gli attributi come numerici}\label{subsub:ibk:numeric}

Applicando gli stessi parametri per configurare il numero di vicini (tutti i numeri dispari nel range \(1\)-\(11\), con \emph{distanza euclidea}), i risultati più rilevanti sono con \texttt{KNN=3} e \texttt{KNN=5}:
infatti, se ad esempio con \texttt{KNN=1} (opzione di default) i risultati sono leggermente peggiori rispetto all'utilizzo dei dati in formato categorico, i seguenti risultati sono invece maggiormente rilevanti:

\begin{itemize}
  \item con \texttt{KNN=3} (\Cref{fig:ibk:3-num}), si ottengono valori di \emph{precision} e di \emph{recall} per la classe ``\texttt{O}'' migliori;
  \item con \texttt{KNN=5} (\Cref{fig:ibk:5-num}), si raggiunge la massimizzazione di \emph{ROC}.
\end{itemize}

% \begin{figure}[htbp]
%   \centering
%   \adjincludegraphics[width=\linewidth,trim=0 {.07\width} {.285\width} {.32\height},clip]{fig/ibk.eps}%
%   \caption{Output di \texttt{IBk} con \texttt{KNN=1} utilizzando gli attributi come numerici}%
%   \label{fig:ibk:1-num}
% \end{figure}

\begin{figure}[H]
  \centering
  \adjincludegraphics[width=\linewidth,trim=0 {.07\width} {.285\width} {.32\height},clip]{fig/ibk3-num.eps}%
  \caption{Output di \texttt{IBk} con \texttt{KNN=3} utilizzando gli attributi come numerici}%
  \label{fig:ibk:3-num}
\end{figure}

\begin{figure}[H]
  \centering
  \adjincludegraphics[width=\linewidth,trim=0 {.07\width} {.285\width} {.32\height},clip]{fig/ibk5-num.eps}%
  \caption{Output di \texttt{IBk} con \texttt{KNN=5} utilizzando gli attributi come numerici}%
  \label{fig:ibk:5-num}
\end{figure}

Al netto di ciò, si può dire che l'utilizzo degli attributi come numerici permette di avere effettivamente risultati migliori,
tuttavia il modello arranca ancora nel riconoscimento degli elementi della classe ``\texttt{O}''.
Le ragioni di questo comportamento sono molto probabilmente non solo dovute allo sbilanciamento nelle classi di output,
ma anche alla mancanza di una separazione netta tra i dati a livello di valori degli attributi.

% Ritenendo di poter essere sulla buona strada, si è provato a effettuare un cambio di metrica per misurare la distanza tra punti (ovvero i dati) nello spazio:
% tra le metriche a disposizione nella workbench, si è provata la \emph{distanza di Čebyšëv} (\texttt{ChebyshevDistance} in Weka), che misura la distanza tra due vettori come la maggiore tra le differenze dei singoli attributi.
% Nelle~\Cref{fig:ibk:3-num-che,fig:ibk:5-num-che} sono riportati i risultati per \texttt{KNN=3} e \texttt{KNN=5}, che però non mostrano miglioramenti tali da poter considerare l'algoritmo particolarmente utile per il caso di studio.

% \begin{figure}[H]
%   \centering
%   \adjincludegraphics[width=0.9\linewidth,trim=0 {.1\width} {.285\width} {.32\height},clip]{fig/ibk3-num-che.eps}%
%   \caption{Output di \texttt{IBk} con \texttt{KNN=3} utilizzando attributi numerici e \emph{distanza di Čebyšëv}}%
%   \label{fig:ibk:3-num-che}
% \end{figure}

% \begin{figure}[H]
%   \centering
%   \adjincludegraphics[width=0.9\linewidth,trim=0 {.1\width} {.285\width} {.32\height},clip]{fig/ibk5-num-che.eps}%
%   \caption{Output di \texttt{IBk} con \texttt{KNN=5} utilizzando attributi numerici e \emph{distanza di Čebyšëv}}%
%   \label{fig:ibk:5-num-che}
% \end{figure}

\subsection{Multi-Classificatori}

I classificatori precedentemente descritti non hanno portato a un modello particolarmente efficace;
si è dunque deciso di provare ad utilizzare modelli a multi-classificatori.
Tali classificatori sono infatti noti per essere particolarmente efficaci per problemi in cui classificatori singoli faticano a raggiungere performance accettabili.

Tra le varie possibilità messe a disposizione da Weka, si è scelto di utilizzare due diversi algoritmi:
\emph{Cost-Sensitive Classifier}, modello che permette di gestire dataset sbilanciati in partenza per distribuzioni delle classi e \emph{Adaboost}, classificatore appartenente alla famiglia delle tecniche di \emph{Boosting}.

\subsubsection{Approccio Cost-Sensitive}

I multi-classificatori \emph{cost-sensitive} sono generalmente efficaci nel gestire dataset non bilanciati, come in questo caso;
essi infatti consentono di attribuire un peso alle istanze sbagliate delle varie classi in gioco, eseguendo così una procedura di \emph{model tuning}.

L'implementazione disponibile in Weka, chiamata \texttt{CostSensitiveClassifier},
permette di selezionare un \emph{classificatore} (i cui parametri possono essere settati a piacere) su cui costruire un modello
e una \emph{matrice di costo} di dimensione \(N×N\) (dove \(N\) è il numero di classi in gioco) con la quale è possibile assegnare una differente penalità alle istanze classificate per ogni classe.

Il primo classificatore provato è stato \texttt{J48}, specificando vari valori nella matrice di costo (accrescendo sempre più la penalità dovuta all'errata classificazione di ``\texttt{N}'' come ``\texttt{O}''):
al crescere del peso, effettivamente la classe ``\texttt{O}'' era favorita, anche a scapito di elementi di classe ``\texttt{N}'', che venivano classificati erroneamente come ``\texttt{O}''.
Questa tendenza era attesa e compatibile con il dominio preso in considerazione:
è infatti più utile avere diagnosticate possibili alterazioni sulla situazione clinica che, con ulteriori analisi, si rivelino non vere che non riconoscere problematiche in paziente effettivamente malato.

Il valore che sembra garantire il migliore equilibrio, tra quelli trovati, è con penalità di \(20\);
in~\Cref{fig:cost:j48} sono riportati i risultati.

\begin{figure}[H]
  \centering
  \adjincludegraphics[width=\linewidth,trim=0 0 {.52\width} {.57\height},clip]{fig/cost-j48.eps}%
  \caption{Output di \texttt{CostSensitiveClassifier} con \texttt{J48} \emph{unpruned}}%
  \label{fig:cost:j48}
\end{figure}

Utilizzando invece come classificatore base il \emph{Naïve Bayes}, i risultati migliorano rispetto al solo classificatore bayesiano, tuttavia le performance rimangono inferiori rispetto al modello costruito con J48;
probabilmente nonostante l'approccio \emph{cost-based} migliori l'efficacia del modello \texttt{NaiveBayes}, le problematiche espresse nella~\Cref{subsec:bayes} sono talmente importanti da non rendere il classificatore valido nemmeno così utilizzato.

Infine è stato utilizzato come classificatore base \texttt{IBk}, che aveva garantito i risultati migliori finora.
Applicando i modelli descritti nella~\Cref{subsec:ibk}, alcuni risultati sono considerabili abbastanza validi:
il miglior risultato in assoluto (\Cref{fig:cost:ibk5}) è stato ottenuto utilizzando \texttt{KNN=5}, \emph{distanza euclidea} e penalità per i record mal classificati di ``\texttt{O}'' uguale a \(5\).

\begin{figure}[H]
  \centering
  \adjincludegraphics[width=\linewidth,trim=0 {.03\height} {.55\width} {.57\height},clip]{fig/cost-ibk-5.eps}%
  \caption{Output di \texttt{CostSensitiveClassifier} con \texttt{IBk} con \texttt{KNN=5}}%
  \label{fig:cost:ibk5}
\end{figure}

Osservando la \emph{Confusion Matrix}, si può notare come questo classificatore abbia il più alto numero di veri positivi mai classificati per la classe ``\texttt{O}'',
a discapito però di un elevato numero di istanze di ``\texttt{N}'' classificate erroneamente.
Nonostante questo, i valori di \emph{ROC} e delle altre metriche risultano in media superiori agli altri modelli testato.

I buoni risultati ottenuti da questo classificatori sono dovuti all'applicazione di un insieme di tecniche per ridurre l'impatto dello sbilanciamento delle classi a un modello già adeguato,
creando così un modello che nel complesso risulta abbastanza valido e funzionale.

\subsubsection{Approccio Boosting}

L'ultimo approccio tentato è stato il \emph{boosting}, processo che si basa sulla costruzione di più classificatori attribuendo ogni volta un peso maggiore agli elementi mal classificati al passo precedente.

Come per i \emph{classificatori cost-based}, anche qui è possibile specificare un modello di base per costruire la classificazione:
in modo analogo sono stati testati tutti i tre classificatori base impiegati ai passi precedenti nelle \Cref{subsec:tree,subsec:bayes,subsec:ibk},
ottenendo i risultati migliori, ancora una volta, con \texttt{IBk}.
In \Cref{fig:adaboost:ibk5} sono riportati i risultati ottenuti con \texttt{IBk} come classificatore base, \texttt{KNN=5}, \emph{distanza euclidea} e un numero di iterazioni pari a \(10\).

\begin{figure}[H]
  \centering
  \adjincludegraphics[width=\linewidth,trim=0 {.03\height} {.55\width} {.57\height},clip]{fig/adaboost-ibk-5.eps}%
  \caption{Output di \texttt{AdaboostM1} con \texttt{IBk}, \texttt{KNN=5} e \(10\) iterazioni}%
  \label{fig:adaboost:ibk5}
\end{figure}

I risultati di questo modello sono buoni: \emph{precision} e \emph{recall} sulla classe ``\texttt{O}'' risultano discrete senza intaccare gli alti valori per ``\texttt{N}'',
mentre il valore di \emph{ROC} è il più alto fra tutti i modelli creati fin d'ora. Questo può essere considerato uno dei migliori tra quelli provati per il dataset analizzato.
